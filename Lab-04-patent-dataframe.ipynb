{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2021-09-28 03:44:49,361 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   null|     BE|   null|    null|      1|  null|   269|  6|    69| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070802| 1963| 1096|   null|     US|     TX|    null|      1|  null|     2|  6|    63| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070803| 1963| 1096|   null|     US|     IL|    null|      1|  null|     2|  6|    63| null|       9|    null| 0.3704|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070804| 1963| 1096|   null|     US|     OH|    null|      1|  null|     2|  6|    63| null|       3|    null| 0.6667|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070805| 1963| 1096|   null|     US|     CA|    null|      1|  null|     2|  6|    63| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create copies and aliased versions of the patents and citations tables. While doing this, we also separate out just the patent and postate fields from the patent table to make it easier to manage. We also set aside a full patents table to perform the final join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = citations.alias('tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = patents.alias('tp')\n",
    "tp = tp.select(col(\"PATENT\").alias(\"PCITING\"), col(\"POSTATE\").alias(\"CITING_POSTATE\"))\n",
    "tp1 = patents.alias('tp1')\n",
    "tp2 = tp1.select(col(\"PATENT\").alias(\"PCITED\"), col(\"POSTATE\").alias(\"CITED_POSTATE\"))\n",
    "tp4 = patents.alias(\"tp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the first join on citing patent with our reduced patents dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "join1 = tc.join(tp, tc.CITING == tp.PCITING)\n",
    "j1 = join1.alias('j1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the second join on cited patent with another copy of the reduced patents dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2 = j1.join(tp2, j1.CITED == tp2.PCITED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we filter out the cases where the postate is not the same and also the cases where postate is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "j2 = join2.filter(join2.CITING_POSTATE == join2.CITED_POSTATE)\n",
    "j3 = j2.filter(j2.CITING_POSTATE.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrange the dataframe removing the cited patents as this will simplify the counting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "j4 = j3.select(col(\"CITING\"), col(\"CITING_POSTATE\"), col(\"CITED_POSTATE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then groupBy and count the number of occurrences. This statement will only give us the count and citing patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "j5 = j4.groupBy(col(\"CITING\").alias(\"GCITING\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then join this information back into our citations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "j6 = j4.join(j5, j4.CITING == j5.GCITING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We alias the count column and take only the distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "j7 = j6.select(col(\"CITING\"), col(\"CITING_POSTATE\"), col(\"CITED_POSTATE\"), col(\"count\").alias(\"CO_CITED_COUNT\")).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then join this back with the patent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "j8 = j7.join(tp4, j7.CITING == tp4.PATENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping redundant patent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "j9 = j8.drop(\"PATENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we order the result by the aliased name for count in a descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "j10 = j9.orderBy(col(\"CO_CITED_COUNT\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 03:45:37,046 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 13:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-------------+--------------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| CITING|CITING_POSTATE|CITED_POSTATE|CO_CITED_COUNT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+--------------+-------------+--------------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|5959466|            CA|           CA|           125| 1999|14515|   1997|     US|     CA|    5310|      2|  null|   326|  4|    46|  159|       0|     1.0|   null|  0.6186|    null|  4.8868|  0.0455|   0.044|    null|    null|\n",
      "|5983822|            TX|           TX|           103| 1999|14564|   1998|     US|     TX|  569900|      2|  null|   114|  5|    55|  200|       0|   0.995|   null|  0.7201|    null|   12.45|     0.0|     0.0|    null|    null|\n",
      "|6008204|            CA|           CA|           100| 1999|14606|   1998|     US|     CA|  749584|      2|  null|   514|  3|    31|  121|       0|     1.0|   null|  0.7415|    null|     5.0|  0.0085|  0.0083|    null|    null|\n",
      "|5952345|            CA|           CA|            98| 1999|14501|   1997|     US|     CA|  749584|      2|  null|   514|  3|    31|  118|       0|     1.0|   null|  0.7442|    null|  5.1102|     0.0|     0.0|    null|    null|\n",
      "|5958954|            CA|           CA|            96| 1999|14515|   1997|     US|     CA|  749584|      2|  null|   514|  3|    31|  116|       0|     1.0|   null|  0.7397|    null|   5.181|     0.0|     0.0|    null|    null|\n",
      "|5998655|            CA|           CA|            96| 1999|14585|   1998|     US|     CA|    null|      1|  null|   560|  1|    14|  114|       0|     1.0|   null|  0.7387|    null|  5.1667|    null|    null|    null|    null|\n",
      "|5936426|            CA|           CA|            94| 1999|14466|   1997|     US|     CA|    5310|      2|  null|   326|  4|    46|  178|       0|     1.0|   null|    0.58|    null| 11.2303|  0.0765|   0.073|    null|    null|\n",
      "|5978329|            CA|           CA|            90| 1999|14550|   1995|     US|     CA|  148925|      2|  null|   369|  2|    24|  145|       0|     1.0|   null|  0.5449|    null| 12.9241|  0.4196|  0.4138|    null|    null|\n",
      "|5925042|            CA|           CA|            90| 1999|14445|   1997|     US|     CA|  733846|      2|  null|   606|  3|    32|  242|       0|     1.0|   null|  0.7382|    null|  8.3471|     0.0|     0.0|    null|    null|\n",
      "|5951547|            CA|           CA|            90| 1999|14501|   1997|     US|     CA|  733846|      2|  null|   606|  3|    32|  242|       0|     1.0|   null|  0.7382|    null|  8.3471|     0.0|     0.0|    null|    null|\n",
      "+-------+--------------+-------------+--------------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "j10.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
