{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"CITING\",\"CITED\"',\n",
       " '3858241,956203',\n",
       " '3858241,1324234',\n",
       " '3858241,3398406',\n",
       " '3858241,3557384']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCitations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
       " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
       " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
       " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
       " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPatents.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first remove the column names row from the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = rddCitations.first()\n",
    "h2 = rddPatents.first()\n",
    "c1 = rddCitations.filter(lambda line: line != h1)\n",
    "p1 = rddPatents.filter(lambda line: line != h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is extracted from the gzip as a comma separated collection of rows, we must first split each row by the comma to get tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = c1.map(lambda x: (x.split(',')[0], x.split(',')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same action with the patents rdds but we also create multiple copies as well as creating reduced patent rdds with just the patent and postate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = p1.map(lambda x: (x.split(',')[0], x))\n",
    "p3 = p1.map(lambda x: (x.split(',')[0], x))\n",
    "p4 = p2.map(lambda x: (x[0], x[1].split(',')[5]))\n",
    "p5 = p3.map(lambda x: (x[0], x[1].split(',')[5]))\n",
    "p6 = p1.map(lambda x: (x.split(',')[0], x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the citations rdd with the reduced patents rdd on the key which is citing patent in the citations rdd and patent in the patents rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = c2.join(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use map to convert this joined result into a key value pair with cited as the new key and (citing, citing_postate) as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = c3.map(lambda x: (x[1][0], (x[0], x[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the citations rdd again with another reduced patents rdd on the key which is cited patent in the citations rdd and patent in the patents rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = c4.join(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then flatten this complicated nested tuple into a regular tuple with 4 elements (citing, citing_postate, cited, cited_postate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6 = c5.map(lambda x: (x[1][0][0], x[1][0][1], x[0], x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then remove the cases where the postates are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = c6.filter(lambda x: x[1] == x[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we remove the cases where the postate is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c8 = c7.filter(lambda x: x[1] != '\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again convert this into a key value pair with citing as the key and (citing_postate, cited, cited_postate) as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c9 = c8.map(lambda x: (x[0], (x[1], x[2], x[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the groupBy and count. This will give us just the citing and count as the result. Citing is still the key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c10 = c9.groupByKey().mapValues(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the final join to add back the patent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c11 = c10.join(p6).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort by descending order of count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "c12 = c11.sortBy(lambda x: x[1][0], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we drop the redundant citing data as it is already in the patent info (This action is not required). Currently the result is in the form of (patent_row_string, count) but we can use map and split to convert this into a larger tuple but I found it is easier to read the data in the current format, so I stored as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c13 = c12.map(lambda x: (x[1][1], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('5959466,1999,14515,1997,\"US\",\"CA\",5310,2,,326,4,46,159,0,1,,0.6186,,4.8868,0.0455,0.044,,',\n",
       "  125),\n",
       " ('5983822,1999,14564,1998,\"US\",\"TX\",569900,2,,114,5,55,200,0,0.995,,0.7201,,12.45,0,0,,',\n",
       "  103),\n",
       " ('6008204,1999,14606,1998,\"US\",\"CA\",749584,2,,514,3,31,121,0,1,,0.7415,,5,0.0085,0.0083,,',\n",
       "  100),\n",
       " ('5952345,1999,14501,1997,\"US\",\"CA\",749584,2,,514,3,31,118,0,1,,0.7442,,5.1102,0,0,,',\n",
       "  98),\n",
       " ('5958954,1999,14515,1997,\"US\",\"CA\",749584,2,,514,3,31,116,0,1,,0.7397,,5.181,0,0,,',\n",
       "  96),\n",
       " ('5998655,1999,14585,1998,\"US\",\"CA\",,1,,560,1,14,114,0,1,,0.7387,,5.1667,,,,',\n",
       "  96),\n",
       " ('5936426,1999,14466,1997,\"US\",\"CA\",5310,2,,326,4,46,178,0,1,,0.58,,11.2303,0.0765,0.073,,',\n",
       "  94),\n",
       " ('5913855,1999,14417,1997,\"US\",\"CA\",733846,2,,606,3,32,242,0,1,,0.7403,,8.3595,0,0,,',\n",
       "  90),\n",
       " ('5739256,1998,13983,1995,\"US\",\"CA\",70060,2,15,528,1,15,453,0,1,,0.8232,,15.1104,0.1124,0.1082,,',\n",
       "  90),\n",
       " ('5925042,1999,14445,1997,\"US\",\"CA\",733846,2,,606,3,32,242,0,1,,0.7382,,8.3471,0,0,,',\n",
       "  90)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c13.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
